---
title: "「すぐに諦めるAI」を卒業させる！長時間稼働エージェントの実装プラクティス"
emoji: "🤖"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["ai", "llm", "agent", "anthropic", "architecture"]
published: true
---

## はじめに

「AI に Web アプリ作成を頼んだら、最初の数ファイルだけ作って『完了しました』と嘘をつかれた」
「コンテキストが溢れて、最後の方は仕様を忘れてしまった」

Web アプリ開発などで AI エージェントを活用しようとした時、**「迷う瞬間、ありませんか？」**
ご自身の開発や AI ツール活用にも即座に応用できる、「タスク完遂力」を高めるための技術仕様書としてまとめました。

---

## 🤖 1. アーキテクチャ：エージェントを「分業」させる

長時間稼働の最大の敵は「コンテキスト溢れ」と「複雑性」です。
これを防ぐためのベストプラクティスは、単一のエージェントですべてを行わせず、役割を明確に分離することです。

### 【Action】2 つのエージェントを定義する

コードを書き始める前に、以下の 2 つの役割を設計しましょう。

1.  **Initializer Agent（初期化・計画担当）**

    - **役割**: 全体像の把握、環境構築、タスクの分解。
    - **成果物**: プロジェクトのボイラープレート作成、Git 初期化、そして**「超詳細なタスクリスト（JSON）」**。

2.  **Coding Agent（実装・実行担当）**
    - **役割**: 分解されたタスクを**「1 つずつ」**実行する。
    - **特徴**: 1 つのタスクが終わるごとに記憶（コンテキスト）がリセットされても問題ないように設計する。

巨大なコンテキストを抱え込ませるのではなく、役割を切り分けることで「今やるべきこと」に集中させるのがポイントです。

---

## 📝 2. 実装のキモ：タスク管理は「JSON」と「Default False」

AI はマークダウンのチェックリストを適当に処理しがちです。
「あれ？ チェック入れたつもりだけど実装してなかった」なんてことを防ぐための鉄則があります。

### 【Action】タスクリストは Markdown ではなく JSON で管理する

Markdown の `- [ ]` は構造が壊れやすいため使用しません。
以下のような JSON スキーマを定義し、Initializer に生成させましょう。

```json
// tasks.json のイメージ
{
  "tasks": [
    {
      "id": 1,
      "title": "ユーザー認証機能の実装",
      "description": "Supabaseを使用したAuth機能を実装する...",
      "requirements": ["ログイン画面", "サインアップ画面"],
      "status": "pending",
      "completed": false
    }
    // ... 他200個以上のタスク
  ]
}
```

### 【Action】完了フラグの初期値はすべて `false` に強制する

AI には「早すぎる完了（Premature Completion）」という癖があります。
これを防ぐため、すべてのタスクの `completed` ステータスをプログラム側で強制的に `false` に初期化します。

AI がコードを書き、テストを通し、明確な根拠を持って `true` に書き換えない限り、プロジェクトは終わりません。これにより、「なんとなく完了」を防ぎます。

---

## 🧠 3. 記憶の永続化：「Git」を外部脳として使う

どんなに高性能な LLM でも、コンテキストウィンドウ（短期記憶）はいずれ溢れます。
そのため、**「Git のコミットログ」を長期記憶として利用**します。

### 【Action】1 タスク 1 コミットのループを作る

Harness（制御スクリプト）で以下のループを回す実装をしましょう。

1.  **Read**: `tasks.json` を読み込み、最初の `completed: false` のタスクを 1 つだけ取得する。
2.  **Prompt**: Coding Agent に対し、「現在の Git の状態」と「今回の 1 タスク」だけを渡して実装させる。
3.  **Test**: 実装後、単体テストだけでなくブラウザテスト（Puppeteer/Playwright 等）を実行させる。
4.  **Commit**: テストが通ったら `git commit` する。このコミットメッセージが次の記憶になる。
5.  **Update**: `tasks.json` の該当タスクを `completed: true` に更新する。

このループにより、コンテキストがリセットされても、AI は「`tasks.json`（残りの仕事）」と「`git log`（これまでの仕事）」を見れば、迷うことなく作業を再開できます。

---

## 🕵️ 4. 検証：`curl` 禁止、ブラウザで見ろ

「コード書きました（動くとは言っていない）」を防ぐための重要なルールです。

### 【Action】検証プロセスを重厚にする

エージェントが「完了」と報告する前に、以下の検証をパスすることを条件にします。

| 検証方法         | 判定  | 理由                                                                              |
| :--------------- | :---: | :-------------------------------------------------------------------------------- |
| **Simple Curl**  | ❌ NG | ステータス 200 が返ってきても、中身が真っ白（Empty）な可能性があるため。          |
| **Browser Test** | ⭕ OK | Playwright などで実際にブラウザを立ち上げ、特定の要素が表示されているか確認する。 |

例えば、「ボタンをクリックしてモーダルが開くか」といった挙動まで含めてテストコードを実行させることで、手戻りを劇的に減らすことができます。

---

## まとめ

長時間稼働エージェントを作る際は、以下の構成（Harness）を組んでみてください。

1.  **役割分担**: 計画係（Initializer）と実行係（Coding）を分ける。
2.  **厳格な管理**: タスクは JSON で管理し、デフォルトは未完了（False）にする。
3.  **外部記憶**: 進捗は Git とファイルシステムに記録し、AI の脳内メモリに依存しない。
4.  **実働テスト**: ブラウザレベルのテストで品質を担保する。

これらを「Harness（手綱）」として実装することで、AI は迷子にならず、数日間にわたる開発作業を完遂できるようになります。
ぜひ、皆さんの AI エージェント開発にも取り入れてみてください！

---

### 参考資料

- [YouTube: AI エージェントが「数日間」自律して開発し続ける？！Claude が公開した新しい仕組みを解説](https://www.youtube.com/watch?v=wXujj978x6o)
- [Anthropic Blog: Effective Harnesses for Long-Running Agents](https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents)
